{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose: Creates .tfrecord files for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util\n",
    "from collections import namedtuple, OrderedDict\n",
    "\n",
    "def class_text_to_int(row_label, label_map):\n",
    "    if row_label in label_map:\n",
    "        return label_map[row_label]['id']\n",
    "    else:\n",
    "        None\n",
    "\n",
    "def split(df, group):\n",
    "    data = namedtuple('data', ['filename', 'object'])\n",
    "    gb = df.groupby(group)\n",
    "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
    "\n",
    "\n",
    "def create_tf_example(group, path, label_map):\n",
    "    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = group.filename.encode('utf8')\n",
    "    image_format = b'jpg'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for index, row in group.object.iterrows():\n",
    "        xmins.append(row['xmin'] / width)\n",
    "        xmaxs.append(row['xmax'] / width)\n",
    "        ymins.append(row['ymin'] / height)\n",
    "        ymaxs.append(row['ymax'] / height)\n",
    "        classes_text.append(row['class'].encode('utf8'))\n",
    "        classes.append(class_text_to_int(row['class'], label_map))\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTFRecord(image_dir, csv_input, output_path, label_map):\n",
    "    writer = tf.python_io.TFRecordWriter(output_path)\n",
    "    path = os.path.join(image_dir)\n",
    "    examples = pd.read_csv(csv_input)\n",
    "    grouped = split(examples, 'filename')\n",
    "    for group in grouped:\n",
    "        tf_example = create_tf_example(group, path, label_map)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLabelMap(label_map_output_path, classes_path):\n",
    "    fout = open(label_map_path, \"w\")\n",
    "    fin = open(classes_path, \"r\")\n",
    "    label_map = {}\n",
    "    item_id = 1\n",
    "    for class_item in fin:\n",
    "        name = class_item.rstrip()\n",
    "        writeLabelMapRecord(fout, item_id, name)\n",
    "        label_map[name] = {\"id\": item_id}\n",
    "        item_id = item_id + 1\n",
    "    fout.close()\n",
    "    fin.close()\n",
    "    return json.loads(json.dumps(label_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeLabelMapRecord(fout, item_id, name):\n",
    "    fout.write(\"item {\\n\")\n",
    "    fout.write(\"  id: %d\\n\" % item_id)\n",
    "    fout.write(\"  name: \\'%s\\'\\n\" % name)\n",
    "    fout.write(\"}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import pdb\n",
    "import os\n",
    "import re\n",
    "\n",
    "def txt_to_csv(img_dir):\n",
    "    txt_list = []\n",
    "    for txt_file in glob.glob(img_dir + '/Label/*.txt'):\n",
    "        f = open(txt_file, \"r\")\n",
    "        \n",
    "        \n",
    "        for row in f:\n",
    "            # parse row eg:  Apple, 1232, 343, 234, 234\n",
    "            row_items = re.split(r' (?=[0-9])', row)\n",
    "            # row_items = row.split(\" \")\n",
    "            value = (os.path.splitext(os.path.basename(f.name))[0] + '.jpg',\n",
    "                    row_items[0],\n",
    "                    int(float(row_items[1])),\n",
    "                    int(float(row_items[2])),\n",
    "                    int(float(row_items[3])),\n",
    "                    int(float(row_items[4].rstrip())),\n",
    "                    )\n",
    "            txt_list.append(value)\n",
    "        f.close()\n",
    "    column_name = ['filename', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "    txt_df = pd.DataFrame(txt_list, columns=column_name)\n",
    "    return txt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSingularCSV(output_path, img_root_dir):\n",
    "    df = pd.DataFrame(columns=['filename', 'class', 'xmin', 'ymin', 'xmax', 'ymax'])\n",
    "    for (dirpath, dirnames, filenames) in os.walk(img_root_dir):\n",
    "        for directory in dirnames:\n",
    "            txt_df = txt_to_csv(os.path.join(dirpath,directory))\n",
    "            df = df.append(txt_df,ignore_index=True)\n",
    "    df.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import shutil\n",
    "\n",
    "def flattenDirectoryStructure(root_path):\n",
    "    all_files = []\n",
    "    for root, _dirs, files in itertools.islice(os.walk(root_path), 1, None):\n",
    "        for filename in files:\n",
    "            if(filename != \".DS_Store\"):\n",
    "                all_files.append(os.path.join(root, filename))\n",
    "    for filename in all_files:\n",
    "        shutil.move(filename, os.path.join(root_path, os.path.basename(filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create label map\n",
    "label_map_path = '/Users/Shanth/Documents/instaFresh_ml/data/labelMap.pbtxt'\n",
    "classes_path = '/Users/Shanth/Documents/instaFresh_ml/classes.txt'\n",
    "label_map = createLabelMap(label_map_path, classes_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train set\n",
    "# create csv file\n",
    "train_root_path = '/Users/Shanth/OIDv4_ToolKit/OID/Dataset/train'\n",
    "train_csv_path = '/Users/Shanth/Documents/instaFresh_ml/data/train.csv'\n",
    "createSingularCSV(train_csv_path, train_root_path)\n",
    "\n",
    "# flatten images directory\n",
    "train_images_path = '/Users/Shanth/Documents/instaFresh_ml/data/train'\n",
    "flattenDirectoryStructure(train_images_path)\n",
    "\n",
    "train_record_path = '/Users/Shanth/Documents/instaFresh_ml/data/train.record'\n",
    "createTFRecord(train_images_path, train_csv_path, train_record_path, label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set\n",
    "# create csv file\n",
    "test_root_path = '/Users/Shanth/OIDv4_ToolKit/OID/Dataset/test'\n",
    "test_csv_path = '/Users/Shanth/Documents/instaFresh_ml/data/test.csv'\n",
    "createSingularCSV(test_csv_path, test_root_path)\n",
    "\n",
    "# Flatten\n",
    "test_images_path = '/Users/Shanth/Documents/instaFresh_ml/data/test'\n",
    "flattenDirectoryStructure(test_images_path)\n",
    "\n",
    "# create record\n",
    "test_record_path = '/Users/Shanth/Documents/instaFresh_ml/data/test.record'\n",
    "createTFRecord(test_images_path, test_csv_path, test_record_path, label_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
